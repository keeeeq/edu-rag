# 知识点 6: 查询分类器

> 📍 **核心文件**: `rag_qa/core/query_classifier.py` + `app.py`  
> ⏱️ **学习时间**: 约 20-30 分钟  
> 🎯 **重要性**: ⭐⭐ (可选的预处理层)

> ⚠️ **优化版说明**: 本模块在优化版中仍然保留,但调用时机有变化:
> - **原版**: 所有查询都先分类
> - **优化版**: 主要用于日常问候语的快速响应,专业咨询进入BM25→RAG流程

---

## 🤔 核心问题：为什么需要查询分类器？

### 问题场景

```
用户问题分为两类：

1️⃣ 通用知识：
   - "1+1等于几？"
   - "Python是什么语言？"
   - "写一个排序算法"
   → LLM 自己就能回答，无需检索知识库

2️⃣ 专业咨询：
   - "AI课程的学费是多少？"
   - "你们的师资力量如何？"
   - "如何报名JAVA课程？"
   → 需要检索知识库才能回答
```

**不分类的问题**：
- ❌ 所有问题都检索 → 浪费资源（通用知识问题也检索）
- ❌ 所有问题都不检索 → 无法回答专业问题

**分类后的好处**：
- ✅ 通用知识直接问 LLM → 省时省钱
- ✅ 专业咨询走 RAG 流程 → 答案准确

---

## 第一部分：BERT 分类器架构

### 🏗️ 核心组件

```python
class QueryClassifier:
    def __init__(self):
        # 1. BERT 分词器
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
        
        # 2. BERT 分类模型（2分类）
        self.model = BertForSequenceClassification.from_pretrained(
            "bert-base-chinese", 
            num_labels=2  # 通用知识(0) vs 专业咨询(1)
        )
        
        # 3. 标签映射
        self.label_map = {"通用知识": 0, "专业咨询": 1}
```

**为什么用 BERT？**
- ✅ 强大的中文语义理解能力
- ✅ 预训练模型，直接微调即可
- ✅ 推理速度快（相比调用 LLM）

---

## 第二部分：分类流程详解

### 🔍 预测流程

**代码位置**: `query_classifier.py` 第 135-160 行

```python
def predict_category(self, query):
    # 步骤1: 分词 + 编码
    inputs = self.tokenizer(
        query,
        return_tensors="pt",      # 返回 PyTorch 张量
        truncation=True,          # 截断过长文本
        padding=True,             # 填充到固定长度
        max_length=128            # 最大长度
    ).to(self.device)
    
    # 步骤2: 模型推理
    with torch.no_grad():  # 不计算梯度（推理模式）
        outputs = self.model(**inputs)
    
    # 步骤3: 获取预测结果
    logits = outputs.logits  # [batch_size, num_labels]
    predicted_label = torch.argmax(logits, dim=-1).item()  # 取最大概率的标签
    
    # 步骤4: 转为可读标签
    label_name = [k for k, v in self.label_map.items() if v == predicted_label][0]
    
    return label_name  # "通用知识" 或 "专业咨询"
```

### 💡 关键步骤解析

#### 步骤 1：文本编码

```python
输入："AI课程的学费是多少？"
       ↓ Tokenizer
{
    "input_ids": [101, 872, 6117, 4923, ...],  # Token ID
    "attention_mask": [1, 1, 1, ...],          # 注意力掩码
    "token_type_ids": [0, 0, 0, ...]           # 句子类型
}
```

**参数说明**：
- `truncation=True`: 文本超过 128 字符时截断
- `padding=True`: 不足 128 字符时填充
- `max_length=128`: 固定输入长度

#### 步骤 2：BERT 推理

```
Token IDs → BERT 编码器 → [CLS] 向量 → 分类头 → Logits

Logits = [0.2, 0.8]
         ↑    ↑
    通用知识  专业咨询
```

#### 步骤 3：取最大值

```python
logits = [0.2, 0.8]
predicted_label = argmax([0.2, 0.8]) = 1  # 索引1
→ 标签映射: 1 → "专业咨询"
```

---

## 第三部分：模型训练（可选）

### 📚 训练数据格式

**数据位置**: `rag_qa/data/model/model_generic_2000.json`

```json
{"query": "什么是RESTful API？", "label": "通用知识"}
{"query": "写一个Python函数计算斐波那契数列", "label": "通用知识"}
{"query": "AI课程的学费是多少？", "label": "专业咨询"}
{"query": "你们的课程大纲是什么？", "label": "专业咨询"}
```

### 🔧 训练流程

**代码位置**: 第 76-133 行

```python
def train_model(self, data_file="model_generic_2000.json"):
    # 步骤1: 加载数据
    with open(data_file, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f.readlines()]
    
    questions = [item['query'] for item in data]
    labels = [self.label_map[item['label']] for item in data]
    
    # 步骤2: 划分训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(
        questions, labels, 
        test_size=0.2,      # 20% 测试集
        random_state=42
    )
    
    # 步骤3: 编码数据
    train_encodings = self.tokenizer(X_train, truncation=True, padding=True)
    test_encodings = self.tokenizer(X_test, truncation=True, padding=True)
    
    # 步骤4: 创建 Dataset
    train_dataset = QueryDataset(train_encodings, y_train)
    test_dataset = QueryDataset(test_encodings, y_test)
    
    # 步骤5: 配置训练参数
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=3,           # 训练轮数
        per_device_train_batch_size=16,  # 批次大小
        learning_rate=2e-5,           # 学习率
        logging_steps=10
    )
    
    # 步骤6: 训练
    trainer = Trainer(
        model=self.model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset
    )
    trainer.train()
    
    # 步骤7: 保存模型
    self.save_model()
```

---

## 第四部分：局限性与改进方向

### ⚠️ 当前实现的局限性

#### 1. 训练数据覆盖范围窄

```python
训练数据只包含：
✅ 技术概念问题 → "通用知识"
✅ 教育机构咨询 → "专业咨询"

但无法识别：
❌ 个人文档查询（如"我的简历中的实习经历"）
❌ 闲聊（如"你好吗？"）
❌ 其他领域的专业问题
```

**您之前遇到的问题**：
```
查询："管中正是我，我的实习经历？"
→ 分类为"通用知识"（误判）
→ 原因：训练数据没有这类查询
```

#### 2. 二分类过于简单

```
理想的分类：
- 通用知识
- 专业咨询（知识库查询）
- 个人文档查询
- 闲聊
- ...

当前实现：只有 2 类
```

#### 3. 依赖训练数据质量

```
训练数据有偏 → 模型有偏

例如：
训练数据中"课程"相关的都是"专业咨询"
→ 模型可能把所有带"课程"的问题都分类为"专业咨询"
```

---

### 🔧 改进方向

#### 改进 1：扩展为多分类

```python
self.label_map = {
    "通用知识": 0, 
    "知识库查询": 1,  # 专业咨询 + 个人文档
    "闲聊": 2,
    "无效问题": 3
}
```

#### 改进 2：基于规则的混合判断

```python
def predict_category(self, query):
    # 规则1: 检测关键词
    if any(keyword in query for keyword in ["简历", "文档", "我的"]):
        return "知识库查询"
    
    # 规则2: 检测学科过滤
    if source_filter:  # 用户指定了学科
        return "知识库查询"
    
    # 规则3: 其他情况用 BERT
    return self.bert_predict(query)
```

**在 `rag_system.py` 中实现**（见知识点 2）：
```python
# 已经采用了这个方案！
if source_filter:
    logger.info("检测到学科过滤，跳过分类，直接执行 RAG")
    query_category = "专业咨询"
```

#### 改进 3：使用更强的模型

```python
# 当前：BERT（轻量级）
BertForSequenceClassification

# 升级：RoBERTa（更强）
RobertaForSequenceClassification

# 终极：直接用 LLM 分类（准确但慢）
llm("分类以下问题：{query}")
```

---

## 第五部分：实际应用建议

### 🎯 什么时候需要查询分类器？

#### ✅ 适合使用的场景：

1. **知识库明确**
   - 知识库只包含特定领域内容
   - 能明确区分"需要检索"和"不需要检索"

2. **成本敏感**
   - LLM 调用成本高
   - 需要减少不必要的检索

3. **性能要求高**
   - 需要快速响应
   - BERT 推理比 LLM 快很多

#### ❌ 不需要的场景：

1. **知识库是通用的**
   - 所有问题都可能相关
   - 分类意义不大

2. **用户明确指定**
   - 用户已经选择了学科分类
   - 不需要再次判断

3. **LLM 成本可接受**
   - 直接检索不会造成资源浪费

---

### 💡 最佳实践：跳过分类器

根据您的项目实际情况：

```python
# 您之前的做法（最简单有效）
def generate_answer(self, query, source_filter=None):
    # 直接跳过分类，所有问题都走 RAG
    # query_category = self.query_classifier.predict_category(query)
    
    logger.info("查询为专业咨询，执行 RAG 流程")
    strategy = self.strategy_selector.select_strategy(query)
    context_docs = self.retrieve_and_merge(query, source_filter, strategy)
    ...
```

**理由**：
- ✅ 简单：无需维护训练数据
- ✅ 准确：不会误判
- ✅ 灵活：适用所有类型的查询

**代价**：
- ❌ 通用知识问题也会检索（但检索失败后 LLM 仍能回答）

---

## ✅ 核心概念检查清单

- [x] **分类器的作用**：区分通用知识和专业咨询
- [x] **BERT 架构**：分词器 + 分类模型
- [x] **预测流程**：编码 → 推理 → argmax
- [x] **训练流程**（可选）：数据准备 → 训练 → 保存
- [x] **局限性**：训练数据覆盖范围、二分类过于简单
- [x] **改进方向**：多分类、规则混合、更强模型
- [x] **实际建议**：根据场景决定是否使用

---

## 📊 查询分类器 vs 其他方案对比

| 方案 | 准确性 | 速度 | 成本 | 维护难度 |
|------|-------|------|------|---------|
| **BERT 分类器** | 中 | 快 | 低 | 高（需维护训练数据） |
| **LLM 分类** | 高 | 慢 | 高 | 低（改 Prompt 即可） |
| **规则判断** | 低 | 最快 | 最低 | 中（规则可能很多） |
| **混合方案** | 中高 | 中 | 低 | 中 |
| **不分类** | - | 快 | 中 | 最低 |

**推荐**：
- 小项目 / 原型：**不分类**或**规则判断**
- 大项目 / 成本敏感：**BERT 分类器**或**混合方案**
- 追求准确性：**LLM 分类**

---

## 🎓 总结

查询分类器是一个**可选的优化组件**，而不是 RAG 的核心必需：

- ✅ **优点**：节省资源、提高响应速度
- ❌ **缺点**：可能误判、需要维护训练数据
- 💡 **建议**：根据实际场景决定是否使用

**您的做法（注释掉分类器）是完全合理的！** 这样可以：
- 避免误判
- 简化系统
- 保证所有查询都能被正确处理

---

**上一个知识点**: [05_Prompt工程.md](./05_Prompt工程.md)  
**下一个知识点**: [07_文档加载器.md](./07_文档加载器.md)
