# 知识点 3: 检索策略选择器

> 📍 **核心文件**: `rag_qa/core/strategy_selector.py`  
> ⏱️ **学习时间**: 约 30-40 分钟  
> 🎯 **重要性**: ⭐⭐⭐⭐ (RAG 的智能调度层)

> ⚠️ **优化版说明**: 本模块在优化版中的调用时机:
> - BM25检索无结果后,才进入RAG流程
> - 此时策略选择器决定使用哪种检索策略

---

## 🤔 核心问题：为什么需要策略选择器？

### 问题场景对比

| 问题类型 | 例子 | 最佳策略 | 如果用错策略 |
|---------|------|---------|------------|
| 明确查询 | "AI课程学费是多少？" | 直接检索 | ✅ 其他策略也能work |
| 抽象查询 | "AI在教育的应用？" | HyDE | ❌ 直接检索可能找不到 |
| 复杂比较 | "比较AI和Java课程" | 子查询 | ❌ 直接检索遗漏信息 |
| 冗长描述 | "我想学AI但不知道..." | 回溯问题 | ❌ 直接检索噪音太多 |

**核心价值**：
- ✅ 自动为不同问题选择最佳检索方式
- ✅ 提高检索准确率和召回率
- ✅ 用户无需了解技术细节

---

## 第一部分：策略选择器的架构

### 🏗️ 整体设计

```python
class StrategySelector:
    def __init__(self):
        # 1. 初始化LLM客户端（用于策略判断）
        self.client = OpenAI(...)
        
        # 2. 加载策略选择的Prompt模板
        self.strategy_prompt_template = self._get_strategy_prompt()
    
    def select_strategy(self, query):
        # 3. 根据查询选择策略
        strategy = self.call_dashscope(self.strategy_prompt_template.format(query=query))
        return strategy
```

**核心思想**：用 LLM 来判断应该用哪种策略！

### 💡 为什么用 LLM 做策略选择？

**传统方法**（基于规则）：
```python
if "比较" in query or "和" in query:
    return "子查询检索"
elif len(query) > 50:
    return "回溯问题检索"
else:
    return "直接检索"
```
❌ 问题：规则太死板，无法理解语义

**LLM 方法**（语义理解）：
```python
# LLM 可以理解问题的真实意图
query = "AI和Java哪个更适合初学者？"
→ LLM 理解：这是比较类问题
→ 返回："子查询检索"
```
✅ 优势：灵活、准确、可扩展

---

## 第二部分：四种检索策略详解 ⭐⭐⭐

### 策略 1：直接检索（默认策略）

**代码位置**: Prompt 模板第 61-68 行

```
描述：对用户查询直接进行检索，不进行任何增强处理。

适用场景：查询意图明确，需要从知识库中检索特定信息的问题

示例：
- 查询：AI 学科学费是多少？
- 策略：直接检索
```

**工作流程**：
```
用户问题："AI课程的学费是多少？"
         ↓
    直接向量化
         ↓
    hybrid_search_with_rerank
         ↓
    返回相关文档
```

**优点**：
- ✅ 最简单、最快速
- ✅ 对明确问题效果好

**缺点**：
- ❌ 无法处理抽象问题
- ❌ 复杂问题效果差

---

### 策略 2：假设问题检索（HyDE）⭐

**代码位置**: Prompt 模板第 69-74 行

```
描述：使用 LLM 生成一个假设的答案，然后基于假设答案进行检索。

适用场景：查询较为抽象，直接检索效果不佳的问题

示例：
- 查询：人工智能在教育领域的应用有哪些？
- 策略：假设问题检索
```

**工作流程**：
```
用户问题："人工智能在教育领域的应用有哪些？"
         ↓
    LLM生成假设答案
    "人工智能在教育领域的应用包括智能辅导系统、
     自动批改作业、个性化学习推荐、学习分析..."
         ↓
    用假设答案做向量化和检索
         ↓
    返回与假设答案相似的真实文档
```

**核心原理**：
```
问题空间 vs 答案空间

问题："XX的应用有哪些？"
答案："XX的应用包括A、B、C..."

在向量空间中：
答案 ↔ 答案 的相似度 > 问题 ↔ 答案 的相似度
```

**实际代码（在 `rag_system.py`）**：
```python
def _retrieve_with_hyde(self, query, source_filter):
    # 1. 生成假设答案
    hyde_prompt_template = RAGPrompts.hyde_prompt()
    hypo_answer = self.llm(hyde_prompt_template.format(query=query)).strip()
    logger.info(f"HyDE 生成的假设答案: '{hypo_answer}'")
    
    # 2. 用假设答案检索
    return self.vector_store.hybrid_search_with_rerank(
        hypo_answer,  # ← 注意：这里用的是假设答案，不是原问题
        k=conf.RETRIEVAL_K, 
        source_filter=source_filter
    )
```

**优点**：
- ✅ 对抽象问题效果好
- ✅ 提高语义匹配度

**缺点**：
- ❌ 需要额外的 LLM 调用（成本高）
- ❌ 假设答案可能偏离

---

### 策略 3：子查询检索 🔀

**代码位置**: Prompt 模板第 75-80 行

```
描述：将复杂的用户查询拆分为多个简单的子查询，分别检索并合并结果。

适用场景：查询涉及多个实体或方面，需要分别检索不同信息的问题

示例：
- 查询：比较 Milvus 和 Zilliz Cloud 的优缺点。
- 策略：子查询检索
```

**工作流程**：
```
原问题："比较AI和Java课程的学费、学时和就业前景"
         ↓
    LLM拆分成子查询
    - 子查询1："AI课程的学费是多少？"
    - 子查询2："Java课程的学费是多少？"
    - 子查询3："AI课程的学时是多少？"
    - 子查询4："Java课程的学时是多少？"
    - ...
         ↓
    分别检索每个子查询
         ↓
    合并并去重
         ↓
    返回所有相关文档
```

**实际代码（在 `rag_system.py`）**：
```python
def _retrieve_with_subqueries(self, query, source_filter):
    # 1. 生成子查询
    subquery_prompt_template = RAGPrompts.subquery_prompt()
    subqueries_text = self.llm(subquery_prompt_template.format(query=query)).strip()
    subqueries = [q.strip() for q in subqueries_text.split("\n") if q.strip()]
    logger.info(f"生成的子查询: {subqueries}")
    
    # 2. 分别检索
    all_docs = []
    for sub_q in subqueries:
        docs = self.vector_store.hybrid_search_with_rerank(
            sub_q, 
            k=conf.CANDIDATE_M//2,  # 每个子查询返回M/2个文档
            source_filter=source_filter
        )
        all_docs.extend(docs)
    
    # 3. 去重
    unique_docs_dict = {doc.page_content: doc for doc in all_docs}
    unique_docs = list(unique_docs_dict.values())
    
    return unique_docs
```

**优点**：
- ✅ 覆盖多个方面
- ✅ 减少信息遗漏

**缺点**：
- ❌ 多次检索，耗时长
- ❌ 可能检索过多无关文档

---

### 策略 4：回溯问题检索 🔄

**代码位置**: Prompt 模板第 81-86 行

```
描述：将复杂的用户查询转化为更基础、更易于检索的问题，然后进行检索。

适用场景：查询较为复杂，需要简化后才能有效检索的问题

示例：
- 查询：我有一个包含 100 亿条记录的数据集，想把它存储到 Milvus 中进行查询。可以吗？
- 策略：回溯问题检索
```

**工作流程**：
```
原问题："我在某公司实习，需要开发一个推荐系统，想了解AI课程是否涵盖推荐算法的内容，
         以及学完后能否胜任这类工作，还有学费是否能用公司培训额度支付..."
         ↓
    LLM简化问题
    "AI课程包含推荐算法吗？"
         ↓
    用简化后的问题检索
         ↓
    返回相关文档
```

**实际代码（在 `rag_system.py`）**：
```python
def _retrieve_with_backtracking(self, query, source_filter):
    # 1. 简化问题
    backtrack_prompt_template = RAGPrompts.backtracking_prompt()
    simplified_query = self.llm(backtrack_prompt_template.format(query=query)).strip()
    logger.info(f"生成的回溯问题: '{simplified_query}'")
    
    # 2. 用简化后的问题检索
    return self.vector_store.hybrid_search_with_rerank(
        simplified_query,  # ← 注意：这里用的是简化后的问题
        k=conf.RETRIEVAL_K, 
        source_filter=source_filter
    )
```

**核心思想**：
```
复杂问题 = 核心问题 + 噪音

原问题："我想学AI，但我数学不好，请问课程难度大吗，学费贵不贵，学完能找到工作吗..."
              ↓ 提取核心
简化后："AI课程的难度和学费？"
```

**优点**：
- ✅ 去除噪音，提高精确度
- ✅ 聚焦核心问题

**缺点**：
- ❌ 可能丢失细节信息
- ❌ 简化可能不准确

---

## 第三部分：策略选择的 Prompt 工程 ⭐⭐⭐

### 🎨 Prompt 模板设计

**代码位置**: 第 53-92 行

```python
def _get_strategy_prompt(self):
    return PromptTemplate(
        template="""
        你是一个智能助手，负责分析用户查询 {query}，并从以下四种检索增强策略中选择一个最适合的策略，直接返回策略名称，不需要解释过程。

        以下是几种检索增强策略及其适用场景：

        1. 直接检索：...
        2. 假设问题检索（HyDE）：...
        3. 子查询检索：...
        4. 回溯问题检索：...

        根据用户查询 {query}，直接返回最适合的策略名称，例如 "直接检索"。不要输出任何分析过程或其他内容。
        """,
        input_variables=["query"],
    )
```

### 💡 Prompt 设计的关键要素

#### 1. 明确的任务描述
```
你是一个智能助手，负责分析用户查询 {query}，
并从以下四种检索增强策略中选择一个最适合的策略
```
✅ 清晰定义角色和目标

#### 2. 详细的策略说明
```
1. 直接检索：
   * 描述：...
   * 适用场景：...
   * 示例：...
```
✅ 提供具体示例帮助 LLM 理解

#### 3. 严格的输出格式
```
直接返回策略名称，例如 "直接检索"。
不要输出任何分析过程或其他内容。
```
✅ 避免 LLM 输出多余内容

#### 4. 低温度参数
```python
temperature=0.1  # 降低随机性，保证稳定输出
```
✅ 同样的问题，返回一致的策略

---

## 第四部分：核心方法深入解析

### 🔧 `select_strategy()` 方法

**代码位置**: 第 95-99 行

```python
def select_strategy(self, query):
    # 1. 格式化Prompt，插入用户查询
    prompt = self.strategy_prompt_template.format(query=query)
    
    # 2. 调用LLM
    strategy = self.call_dashscope(prompt)
    
    # 3. 记录日志
    logger.info(f"为查询 '{query}' 选择的检索策略：{strategy}")
    
    return strategy
```

### 🤖 `call_dashscope()` 方法

**代码位置**: 第 31-50 行

```python
def call_dashscope(self, prompt):
    try:
        # 创建聊天完成请求
        completion = self.client.chat.completions.create(
            model=Config().LLM_MODEL,  # qwen3-max
            messages=[
                {"role": "system", "content": "你是一个有用的助手。"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1  # 低温度，保证输出稳定
        )
        
        # 返回LLM的回复
        return completion.choices[0].message.content if completion.choices else "直接检索"
    
    except Exception as e:
        logger.error(f"DashScope API 调用失败: {e}")
        return "直接检索"  # 默认策略：最安全的选择
```

**关键设计**：
- ✅ **异常处理**：API 失败时返回默认策略
- ✅ **兜底机制**：确保总是能返回一个有效策略
- ✅ **低温度**：temperature=0.1 保证稳定性

---

## 🎯 实战示例

### 示例 1：明确查询

```python
query = "AI课程的学费是多少？"

# 策略选择器的工作流程
strategy_selector = StrategySelector()
strategy = strategy_selector.select_strategy(query)

# LLM 的判断过程（内部）
"""
分析：
- 问题明确："学费是多少"
- 目标单一：只问学费
- 不涉及比较或复杂推理
→ 选择：直接检索
"""

print(strategy)  # 输出："直接检索"
```

---

### 示例 2：抽象查询

```python
query = "人工智能在教育领域的应用有哪些？"

strategy = strategy_selector.select_strategy(query)

# LLM 的判断过程
"""
分析：
- 问题抽象：没有具体目标
- 开放性问题：需要列举
- 直接检索可能找不到完整答案
→ 选择：假设问题检索
"""

print(strategy)  # 输出："假设问题检索"
```

---

### 示例 3：比较查询

```python
query = "比较AI和Java课程的学费、学时和就业前景"

strategy = strategy_selector.select_strategy(query)

# LLM 的判断过程
"""
分析：
- 涉及两个实体：AI课程、Java课程
- 涉及多个方面：学费、学时、就业前景
- 需要分别检索再合并
→ 选择：子查询检索
"""

print(strategy)  # 输出："子查询检索"
```

---

### 示例 4：复杂查询

```python
query = "我想学AI但数学不好，不知道能不能学会，而且预算有限，想了解课程难度和学费情况..."

strategy = strategy_selector.select_strategy(query)

# LLM 的判断过程
"""
分析：
- 问题冗长，包含大量背景信息
- 核心问题：课程难度 + 学费
- 其他都是噪音
→ 选择：回溯问题检索
"""

print(strategy)  # 输出："回溯问题检索"
```

---

## 📊 策略选择决策树

```
用户查询
    ↓
┌─────────────────┐
│ 问题是否明确？  │
└─────────────────┘
  是↓        否↓
直接检索   继续判断
            ↓
    ┌─────────────────┐
    │ 是否涉及多方面？│
    └─────────────────┘
      是↓        否↓
    子查询     继续判断
                ↓
        ┌─────────────────┐
        │ 问题是否抽象？  │
        └─────────────────┘
          是↓        否↓
         HyDE    回溯问题检索
```

---

## ✅ 核心概念检查清单

- [x] **策略选择器的作用**：自动为不同问题选择最佳检索方式
- [x] **直接检索**：最简单，适合明确问题
- [x] **HyDE**：用假设答案检索，适合抽象问题
- [x] **子查询**：拆分问题分别检索，适合多方面问题
- [x] **回溯问题**：简化问题，适合复杂冗长的问题
- [x] **Prompt 工程**：设计合理的策略选择 Prompt
- [x] **兜底机制**：API 失败时返回默认策略

---

## 🎓 进阶思考

### Q1: 能否用传统机器学习模型做策略选择？

**可以，但不推荐**：
- ✅ 优点：推理速度快（无需调用 LLM）
- ❌ 缺点：需要大量标注数据，泛化能力差

**LLM 方法的优势**：
- ✅ 零样本学习（few-shot prompting）
- ✅ 语义理解能力强
- ✅ 易于调整（修改 Prompt 即可）

### Q2: 策略选择错误怎么办？

**影响**：
- 通常不会完全失败
- 最差情况：检索效果略差于最优策略

**缓解方法**：
1. 提供更多示例在 Prompt 中
2. 使用更强大的 LLM
3. 添加策略验证机制

### Q3: 如何评估策略选择的准确性？

**评估方法**：
1. 人工标注：为测试集标注最佳策略
2. A/B 测试：对比不同策略的检索效果
3. 用户反馈：统计用户满意度

---

## 📚 扩展阅读

1. **Few-shot Learning**: 如何用少量示例教会 LLM
2. **Prompt Engineering Guide**: [https://www.promptingguide.ai/](https://www.promptingguide.ai/)
3. **Query Understanding**: 搜索引擎中的查询理解技术

---

**上一个知识点**: [02_RAG核心流程.md](./02_RAG核心流程.md)  
**下一个知识点**: [04_文档分割策略.md](./04_文档分割策略.md)
